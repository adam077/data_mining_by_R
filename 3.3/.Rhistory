model <- naiveBayes(TF.train, data.train$targets)
a <- predict(model, TF.test)
convert_counts <- function(x) {
x <- ifelse(x > 0, "yes", "no")
x <- factor(x)
return(x)
}
TF.train <- apply(TF.train, MARGIN = 2, convert_counts)
TF.test <- apply(TF.test, MARGIN = 2, convert_counts)
model <- naiveBayes(TF.train, data.train$targets)
a <- predict(model, TF.test)
library(party)
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
table(data.test$CollegePlans, data.test.predict)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
data <- read.csv("data.csv", stringAsFactor=FALSE)
data <- read.csv("data.csv", stringsAsFactors=FALSE)
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentIncome+IQ+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
data.test.predict <- predict(model, newdata = data.test)
data.test.predict
#install.packages("e1071")
library(e1071)
library(class)
library(tm)
library(tmcn)
library(Rwordseg)
docs <- Corpus(
DirSource(
c(
"SogouC.mini/SampleNamed/C000007", "SogouC.mini/SampleNamed/C000008",
"SogouC.mini/SampleNamed/C000010", "SogouC.mini/SampleNamed/C000013",
"SogouC.mini/SampleNamed/C000014", "SogouC.mini/SampleNamed/C000016",
"SogouC.mini/SampleNamed/C000020", "SogouC.mini/SampleNamed/C000022",
"SogouC.mini/SampleNamed/C000023", "SogouC.mini/SampleNamed/C000024"
)
),
readerControl = list(
language='UTF-8'
)
)
data <- data.frame(
ids=c(NA),
targets=c(NA),
contents=c(NA)
);
for(i in 1:length(docs)) {
data[i, 1] <- docs[[i]]$meta$id;
data[i, 2] <- strsplit(docs[[i]]$meta$id, "_")[1]
data[i, 3] <- paste(docs[[i]]$content, collapse = "")
data[i, 3] <- gsub("[A-Za-z]", "", data[i, 3])
}
#随机抽样
#install.packages("sampling")
library(sampling)
sub <- strata(
data,
stratanames=c("targets"),
size=rep(7, 10),
method='srswor'
)
data.train <- data[as.integer(row.names(sub)), ]
index.train <- as.integer(row.names(sub))
data.test <- data[-as.integer(row.names(sub)), ]
processTDM <- function(contents, dictionary=NULL) {
doc <- Corpus(VectorSource(contents))
doc <- tm_map(
doc,
content_transformer(segmentCN),
returnType="tm"
)
doc <- tm_map(doc, stripWhitespace)
doc <- tm_map(doc, removePunctuation)
doc <- tm_map(doc, removeNumbers)
doc <- tm_map(doc, removeWords, stopwords("english"));
doc <- tm_map(doc, removeWords, stopwordsCN());
tdm <- NULL;
if(is.null(dictionary)) {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 2)
)
)
} else {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 2),
dictionary=dictionary
)
)
}
return(tdm);
}
tdm.train <- processTDM(data.train$contents)
TF.train <- as.data.frame(as.matrix(tdm.train))
tdm.test <- processTDM(data.test$contents, tdm.train$dimnames$Terms)
TF.test <- as.data.frame(as.matrix(tdm.test))
convert_counts <- function(x) {
x <- ifelse(x > 0, "yes", "no")
x <- factor(x)
return(x)
}
TF.train <- apply(TF.train, MARGIN = 2, convert_counts)
TF.test <- apply(TF.test, MARGIN = 2, convert_counts)
model <- naiveBayes(TF.train, data.train$targets)
a <- predict(model, TF.test)
View(TF.test)
model <- NaiveBayes(TF.train, factor(data.train$targets))
library(klaR)
install.packages("klaR")
library(klaR)
TF.train[, 'targets'] <- factor(data.train$targets)
model <- NaiveBayes(TF.train, factor(data.train$targets))
a <- predict(model, TF.test)
a
a$class
prop.table(table(data.test$targets, a$class))
table(data.test$targets, a$class)
result <- table(data.test$targets, a$class)
#install.packages("klaR")
library(klaR)
library(tm)
library(tmcn)
library(Rwordseg)
library(sampling)
docs <- Corpus(
DirSource(
c(
"SogouC.mini/SampleNamed/C000007", "SogouC.mini/SampleNamed/C000008",
"SogouC.mini/SampleNamed/C000010", "SogouC.mini/SampleNamed/C000013",
"SogouC.mini/SampleNamed/C000014", "SogouC.mini/SampleNamed/C000016",
"SogouC.mini/SampleNamed/C000020", "SogouC.mini/SampleNamed/C000022",
"SogouC.mini/SampleNamed/C000023", "SogouC.mini/SampleNamed/C000024"
)
),
readerControl = list(
language='UTF-8'
)
)
#对数据做二次处理
data <- data.frame(
ids=c(NA),
targets=c(NA),
contents=c(NA)
);
for(i in 1:length(docs)) {
data[i, 1] <- docs[[i]]$meta$id;
data[i, 2] <- strsplit(docs[[i]]$meta$id, "_")[1]
data[i, 3] <- paste(docs[[i]]$content, collapse = "")
#data[i, 3] <- gsub("[A-Za-z]", "", data[i, 3])
}
#随机抽样
sub <- strata(
data,
stratanames=c("targets"),
size=rep(7, 10),
method='srswor'
)
data.train <- data[as.integer(row.names(sub)), ]
index.train <- as.integer(row.names(sub))
data.test <- data[-as.integer(row.names(sub)), ]
processTDM <- function(contents, dictionary=NULL) {
doc <- Corpus(VectorSource(contents))
doc <- tm_map(
doc,
content_transformer(segmentCN),
returnType="tm"
)
doc <- tm_map(doc, stripWhitespace)
doc <- tm_map(doc, removePunctuation)
doc <- tm_map(doc, removeNumbers)
doc <- tm_map(doc, removeWords, stopwords("english"));
doc <- tm_map(doc, removeWords, stopwordsCN());
tdm <- NULL;
if(is.null(dictionary)) {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 2)
)
)
} else {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 2),
dictionary=dictionary
)
)
}
return(tdm);
}
tdm.train <- processTDM(data.train$contents)
TF.train <- as.data.frame(as.matrix(tdm.train))
tdm.test <- processTDM(data.test$contents, tdm.train$dimnames$Terms)
TF.test <- as.data.frame(as.matrix(tdm.test))
convert_counts <- function(x) {
x <- ifelse(x > 0, "yes", "no")
x <- factor(x)
return(x)
}
TF.train <- apply(TF.train, MARGIN = 2, convert_counts)
TF.test <- apply(TF.test, MARGIN = 2, convert_counts)
TF.train[, 'targets'] <- factor(data.train$targets)
model <- NaiveBayes(TF.train, factor(data.train$targets))
data.test.predict <- predict(model, TF.test)
result <- table(data.test$targets, a$class)
result <- table(data.test$targets, data.test.predict$class)
result
data.train <- data[index.train, ]
data.test <- data[-index.train, ]
table(data.test$targets)
#install.packages("klaR")
library(klaR)
library(tm)
library(tmcn)
library(Rwordseg)
library(sampling)
docs <- Corpus(
DirSource(
c(
"SogouC.mini/SampleNamed/C000007", "SogouC.mini/SampleNamed/C000008",
"SogouC.mini/SampleNamed/C000010", "SogouC.mini/SampleNamed/C000013",
"SogouC.mini/SampleNamed/C000014", "SogouC.mini/SampleNamed/C000016",
"SogouC.mini/SampleNamed/C000020", "SogouC.mini/SampleNamed/C000022",
"SogouC.mini/SampleNamed/C000023", "SogouC.mini/SampleNamed/C000024"
)
),
readerControl = list(
language='UTF-8'
)
)
#对数据做二次处理
data <- data.frame(
ids=c(NA),
targets=c(NA),
contents=c(NA)
);
for(i in 1:length(docs)) {
data[i, 1] <- docs[[i]]$meta$id;
data[i, 2] <- strsplit(docs[[i]]$meta$id, "_")[1]
data[i, 3] <- paste(docs[[i]]$content, collapse = "。")
}
#随机抽样
sub <- strata(
data,
stratanames=c("targets"),
size=rep(7, 10),
method='srswor'
)
index.train <- as.integer(row.names(sub))
data.train <- data[index.train, ]
data.test <- data[-index.train, ]
warnings
warnings()
processTDM <- function(contents, dictionary=NULL) {
doc <- Corpus(VectorSource(contents))
doc <- tm_map(
doc,
content_transformer(segmentCN),
returnType="tm"
)
doc <- tm_map(doc, stripWhitespace)
doc <- tm_map(doc, removePunctuation)
doc <- tm_map(doc, removeNumbers)
doc <- tm_map(doc, removeWords, stopwords("english"));
doc <- tm_map(doc, removeWords, stopwordsCN());
tdm <- NULL;
if(is.null(dictionary)) {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 4)
)
)
} else {
tdm <- DocumentTermMatrix(
doc,
control = list(
wordLengths= c(2, 4),
dictionary=dictionary
)
)
}
return(tdm);
}
tdm.train <- processTDM(data.train$contents)
TF.train <- as.data.frame(as.matrix(tdm.train))
tdm.test <- processTDM(data.test$contents, tdm.train$dimnames$Terms)
TF.test <- as.data.frame(as.matrix(tdm.test))
convert_counts <- function(x) {
x <- ifelse(x > 0, "yes", "no")
x <- factor(x)
return(x)
}
TF.train <- apply(TF.train, MARGIN = 2, convert_counts)
TF.test <- apply(TF.test, MARGIN = 2, convert_counts)
TF.train[, 'targets'] <- factor(data.train$targets)
model <- NaiveBayes(TF.train, factor(data.train$targets))
data.test.predict <- predict(model, TF.test)
result <- table(data.test$targets, data.test.predict$class)
result
data.test.predict
View(TF.test)
table(data.test[10,])
table(TF.test[10, ])
data <- read.csv("data.csv", stringsAsFactors=FALSE)
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
library(klaR)
data <- read.csv("data.csv", stringsAsFactors=FALSE)
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentEncouragement
model <- naiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
model <- NaiveBayes(formula, data.train)
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict), 1)
data.test.predict
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender+ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + ParentIncome + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
plot(data$IQ)
plot(sort(data$IQ))
cut(data$IQ, breaks=c(0, 60, 90, 110, 150))
data$IQCut <- cut(data$IQ, breaks=c(0, 60, 90, 110, 130, 150))
formula=CollegePlans ~ Gender + ParentIncome + IQCut + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data[, 'IQCut'] <- cut(data$IQ, breaks=c(0, 60, 90, 110, 130, 150))
formula=CollegePlans ~ Gender + ParentIncome + IQCut + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncome + IQCut + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + ParentIncome + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
plot(sort(data$ParentIncome))
hist(data$IQ)
hist(data$ParentIncome)
hist(data$IQ)
data[, 'IQCut'] <- cut(data$IQ, breaks=c(0, 90, 110, 120, 150))
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncome + IQCut + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
hist(data$ParentIncome)
data[, 'ParentIncomeCut'] <- cut(data$ParentIncome, breaks=c(0, 5000, 30000, 50000, 80000, 90000))
formula=CollegePlans ~ Gender + ParentIncomeCut + IQCut + ParentEncouragement
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncomeCut + IQCut + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
marks.d <- discretize(data$IQ, method = "interval", breaks = 5)
library(arules)
install.packages("arules")
library(arules)
data[, 'IQD'] <- discretize(data$IQ, method = "interval", breaks = 5)
data[, 'IQD'] <- discretize(data$IQ, method = "interval")
table(data[, 'IQD'])
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncomeCut + IQD + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + IQD + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + IQD + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
data[, 'ParentIncomeD'] <- discretize(data$ParentIncome, method = "interval")
formula=CollegePlans ~ Gender + IQD + ParentIncomeD + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data[, 'ParentIncomeD'] <- discretize(data$ParentIncome, method = "interval")
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + IQD + ParentIncomeD + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
#install.packages("klaR")
library(klaR)
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
formula=CollegePlans ~ Gender + ParentIncome + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
#install.packages("klaR")
library(klaR)
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncome + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
summary(model)
summary(model$tables)
model$tables
library(klaR)
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
library(klaR)
data <- read.csv("data.csv")
total <- nrow(data)
index <- sample(1:total, total*0.7)
data.train <- data[index, ]
data.test <- data[-index, ]
formula=CollegePlans ~ Gender + ParentIncome + IQ + ParentEncouragement
model <- NaiveBayes(formula, data.train)
data.test.predict <- predict(model, newdata = data.test)
table(data.test$CollegePlans, data.test.predict$class)
prop.table(table(data.test$CollegePlans, data.test.predict$class), 1)
